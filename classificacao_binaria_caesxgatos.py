# -*- coding: utf-8 -*-
"""Classificacao_Binaria_CaesXGatos

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_uUYWy7r3NUtkR3188SIsZl3gTKTPubd

Grupo: Mateus Padilha, Breno de Souza e Ian Esteves

# **DESAFIO**

Vamos trabalhar alguns cenários onde utilizaremos RNAs MLP para resolver problemas que envolvem imagens.

# **Classificação binária (cães vs. gatos em baixa resolução)**

## **O problema**

O objetivo é construir e treinar uma Rede Neural Artificial MLP para classificar uma imagem como contendo um `gato` ou um `cachorro`.

## **O Conjunto de Dados**

Utilizaremos o dataset **"Cats vs. Dogs"**, disponível através do `tensorflow_datasets`.

# 1) Classificação binária (cães vs. gatos em baixa resolução)

Queremos que a rede classifique uma imagem como:

0 → Gato

1 → Cachorro

O dataset Cats vs. Dogs do tensorflow_datasets contém imagens coloridas de tamanhos variados, então precisamos padronizar e reduzir a resolução antes de alimentar o MLP.
"""

# ================================================
# PARTE 1 - IMPORTAÇÕES E CONFIGURAÇÃO INICIAL
# ================================================

import tensorflow as tf
import tensorflow_datasets as tfds
from tensorflow.keras import Sequential, regularizers
from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report
import random

# ================================================
# PARTE 2 - CARREGAMENTO DO DATASET
# ================================================

(ds_train, ds_test), ds_info = tfds.load(
    "cats_vs_dogs",
    split=["train[:80%]", "train[80%:]"],  # 80% treino, 20% teste
    as_supervised=True,
    with_info=True
)

print("Informações do Dataset:")
print(ds_info)
print("\nNúmero total de imagens:", ds_info.splits['train'].num_examples)

# ================================================
# PARTE 3 - DISTRIBUIÇÃO E VISUALIZAÇÃO DE AMOSTRAS
# ================================================

cat_count = 0
dog_count = 0

for image, label in tfds.as_numpy(ds_train):
    if label == 0:
        cat_count += 1
    else:
        dog_count += 1

for image, label in tfds.as_numpy(ds_test):
    if label == 0:
        cat_count += 1
    else:
        dog_count += 1

total = cat_count + dog_count
print(f"\n🐱 Total de Gatos: {cat_count}")
print(f"🐶 Total de Cachorros: {dog_count}")
print(f"Total de Imagens: {total}")
print(f"\nDistribuição:")
print(f"Gatos: {cat_count / total:.2%}")
print(f"Cachorros: {dog_count / total:.2%}")

# Visualização de amostras
class_names = ['Gato', 'Cachorro']
plt.figure(figsize=(8, 8))
for i, (image, label) in enumerate(ds_train.take(9)):
    plt.subplot(3, 3, i + 1)
    plt.imshow(image)
    plt.title(class_names[label.numpy()])
    plt.axis('off')
plt.show()

# ================================================
# PARTE 4 - PRÉ-PROCESSAMENTO DAS IMAGENS
# ================================================

BATCH = 64
AUTOTUNE = tf.data.AUTOTUNE

# Normalização e redimensionamento
def preprocess(image, label):
    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))
    image = tf.cast(image, tf.float32) / 255.0
    return image, label

# Data augmentation leve
def augment(image, label):
    image = tf.image.random_flip_left_right(image)
    image = tf.image.random_brightness(image, max_delta=0.1)
    return image, label

# Aplicando pré-processamento
ds_train = ds_train.map(preprocess, num_parallel_calls=AUTOTUNE)
ds_train = ds_train.map(augment, num_parallel_calls=AUTOTUNE)
ds_train = ds_train.shuffle(1000).batch(BATCH).prefetch(AUTOTUNE)

ds_test = ds_test.map(preprocess, num_parallel_calls=AUTOTUNE)
ds_test = ds_test.batch(BATCH).prefetch(AUTOTUNE)

# ================================================
# PARTE 5 - ARQUITETURA DA REDE NEURAL (MLP)
# ================================================

mlp_model = Sequential([
    Flatten(input_shape=(IMG_SIZE, IMG_SIZE, 3)),
    Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)),
    BatchNormalization(),
    Dropout(0.5),

    Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)),
    BatchNormalization(),
    Dropout(0.5),

    Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)),
    Dropout(0.4),

    Dense(1, activation='sigmoid')  # saída binária (Gato x Cachorro)
])

mlp_model.summary()

# ================================================
# PARTE 6 - COMPILAÇÃO E TREINAMENTO DO MODELO
# ================================================

mlp_model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
    loss='binary_crossentropy',
    metrics=['accuracy']
)

early_stop = tf.keras.callbacks.EarlyStopping(
    patience=5, restore_best_weights=True, monitor='val_loss'
)

history = mlp_model.fit(
    ds_train,
    validation_data=ds_test,
    epochs=30,
    callbacks=[early_stop],
    verbose=1
)

# ================================================
# PARTE 7 - AVALIAÇÃO DO MODELO E MÉTRICAS
# ================================================

# Curvas de aprendizado
plt.figure(figsize=(8, 5))
plt.plot(history.history['accuracy'], label='Treino')
plt.plot(history.history['val_accuracy'], label='Validação')
plt.title('Evolução da Acurácia')
plt.xlabel('Épocas')
plt.ylabel('Acurácia')
plt.legend()
plt.show()

# Avaliação final
test_loss, test_acc = mlp_model.evaluate(ds_test)
print(f"Acurácia final no conjunto de teste: {test_acc:.4f}")

# Matriz de confusão
y_true = []
y_pred = []

for images, labels in ds_test:
    preds = mlp_model.predict(images)
    y_true.extend(labels.numpy())
    y_pred.extend((preds > 0.5).astype(int).flatten())

cm = confusion_matrix(y_true, y_pred)
ConfusionMatrixDisplay(cm, display_labels=['Gato', 'Cachorro']).plot(cmap='Blues')
plt.show()

# Relatório de classificação
print("\nRelatório de Classificação:")
print(classification_report(y_true, y_pred, target_names=['Gato', 'Cachorro']))

"""-> Matriz de Confusão

- Acertos do modelo:

  - 1167 gatos foram corretamente classificados como gatos.

  - 1665 cachorros foram corretamente classificados como cachorros.

- Erros do modelo:

  - 1113 gatos foram classificados como cachorros.

  - 707 cachorros foram classificados como gatos.

- O modelo está melhor em identificar cachorros do que gatos:

  - Ele acerta 70% dos cachorros (1665 / (1665+707)) ≈ 70,2%

  - Mas acerta apenas 51% dos gatos (1167 / (1167+1113)) ≈ 51,2%

DOCUMENTAÇÃO RESUMIDA:

1️⃣ PRÉ-PROCESSAMENTO
- Imagens redimensionadas para 64x64 e normalizadas (0–1).
- Data Augmentation (flip horizontal e brilho aleatório) melhora generalização.

2️⃣ ARQUITETURA DA RNA
- Rede MLP densa (sem convolução).
- 3 camadas densas com 512 → 256 → 128 neurônios.
- ReLU nas camadas internas e Sigmoid na saída (classificação binária).
- Regularização L2 e Dropout evitam overfitting.

3️⃣ TREINAMENTO
- Otimizador Adam com LR=0.0001.
- EarlyStopping interrompe antes do overfitting.
- Métrica principal: Acurácia.

4️⃣ AVALIAÇÃO
- Curvas de aprendizado analisam overfitting.
- Matriz de confusão e relatório de classificação mostram erros do modelo.

Com essa configuração, esperou-se acurácia entre 0.60,
mantendo a rede puramente MLP (sem CNNs).

Referências principais de documentação:

-> Slides de Redes Neurais, Gemini e ChatGPT
"""