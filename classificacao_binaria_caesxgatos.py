# -*- coding: utf-8 -*-
"""Classificacao_Binaria_CaesXGatos

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_uUYWy7r3NUtkR3188SIsZl3gTKTPubd

Grupo: Mateus Padilha, Breno de Souza e Ian Esteves

# **DESAFIO**

Vamos trabalhar alguns cenÃ¡rios onde utilizaremos RNAs MLP para resolver problemas que envolvem imagens.

# **ClassificaÃ§Ã£o binÃ¡ria (cÃ£es vs. gatos em baixa resoluÃ§Ã£o)**

## **O problema**

O objetivo Ã© construir e treinar uma Rede Neural Artificial MLP para classificar uma imagem como contendo um `gato` ou um `cachorro`.

## **O Conjunto de Dados**

Utilizaremos o dataset **"Cats vs. Dogs"**, disponÃ­vel atravÃ©s do `tensorflow_datasets`.

# 1) ClassificaÃ§Ã£o binÃ¡ria (cÃ£es vs. gatos em baixa resoluÃ§Ã£o)

Queremos que a rede classifique uma imagem como:

0 â†’ Gato

1 â†’ Cachorro

O dataset Cats vs. Dogs do tensorflow_datasets contÃ©m imagens coloridas de tamanhos variados, entÃ£o precisamos padronizar e reduzir a resoluÃ§Ã£o antes de alimentar o MLP.
"""

# ================================================
# PARTE 1 - IMPORTAÃ‡Ã•ES E CONFIGURAÃ‡ÃƒO INICIAL
# ================================================

import tensorflow as tf
import tensorflow_datasets as tfds
from tensorflow.keras import Sequential, regularizers
from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report
import random

# ================================================
# PARTE 2 - CARREGAMENTO DO DATASET
# ================================================

(ds_train, ds_test), ds_info = tfds.load(
    "cats_vs_dogs",
    split=["train[:80%]", "train[80%:]"],  # 80% treino, 20% teste
    as_supervised=True,
    with_info=True
)

print("InformaÃ§Ãµes do Dataset:")
print(ds_info)
print("\nNÃºmero total de imagens:", ds_info.splits['train'].num_examples)

# ================================================
# PARTE 3 - DISTRIBUIÃ‡ÃƒO E VISUALIZAÃ‡ÃƒO DE AMOSTRAS
# ================================================

cat_count = 0
dog_count = 0

for image, label in tfds.as_numpy(ds_train):
    if label == 0:
        cat_count += 1
    else:
        dog_count += 1

for image, label in tfds.as_numpy(ds_test):
    if label == 0:
        cat_count += 1
    else:
        dog_count += 1

total = cat_count + dog_count
print(f"\nğŸ± Total de Gatos: {cat_count}")
print(f"ğŸ¶ Total de Cachorros: {dog_count}")
print(f"Total de Imagens: {total}")
print(f"\nDistribuiÃ§Ã£o:")
print(f"Gatos: {cat_count / total:.2%}")
print(f"Cachorros: {dog_count / total:.2%}")

# VisualizaÃ§Ã£o de amostras
class_names = ['Gato', 'Cachorro']
plt.figure(figsize=(8, 8))
for i, (image, label) in enumerate(ds_train.take(9)):
    plt.subplot(3, 3, i + 1)
    plt.imshow(image)
    plt.title(class_names[label.numpy()])
    plt.axis('off')
plt.show()

# ================================================
# PARTE 4 - PRÃ‰-PROCESSAMENTO DAS IMAGENS
# ================================================

BATCH = 64
AUTOTUNE = tf.data.AUTOTUNE

# NormalizaÃ§Ã£o e redimensionamento
def preprocess(image, label):
    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))
    image = tf.cast(image, tf.float32) / 255.0
    return image, label

# Data augmentation leve
def augment(image, label):
    image = tf.image.random_flip_left_right(image)
    image = tf.image.random_brightness(image, max_delta=0.1)
    return image, label

# Aplicando prÃ©-processamento
ds_train = ds_train.map(preprocess, num_parallel_calls=AUTOTUNE)
ds_train = ds_train.map(augment, num_parallel_calls=AUTOTUNE)
ds_train = ds_train.shuffle(1000).batch(BATCH).prefetch(AUTOTUNE)

ds_test = ds_test.map(preprocess, num_parallel_calls=AUTOTUNE)
ds_test = ds_test.batch(BATCH).prefetch(AUTOTUNE)

# ================================================
# PARTE 5 - ARQUITETURA DA REDE NEURAL (MLP)
# ================================================

mlp_model = Sequential([
    Flatten(input_shape=(IMG_SIZE, IMG_SIZE, 3)),
    Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)),
    BatchNormalization(),
    Dropout(0.5),

    Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)),
    BatchNormalization(),
    Dropout(0.5),

    Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)),
    Dropout(0.4),

    Dense(1, activation='sigmoid')  # saÃ­da binÃ¡ria (Gato x Cachorro)
])

mlp_model.summary()

# ================================================
# PARTE 6 - COMPILAÃ‡ÃƒO E TREINAMENTO DO MODELO
# ================================================

mlp_model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
    loss='binary_crossentropy',
    metrics=['accuracy']
)

early_stop = tf.keras.callbacks.EarlyStopping(
    patience=5, restore_best_weights=True, monitor='val_loss'
)

history = mlp_model.fit(
    ds_train,
    validation_data=ds_test,
    epochs=30,
    callbacks=[early_stop],
    verbose=1
)

# ================================================
# PARTE 7 - AVALIAÃ‡ÃƒO DO MODELO E MÃ‰TRICAS
# ================================================

# Curvas de aprendizado
plt.figure(figsize=(8, 5))
plt.plot(history.history['accuracy'], label='Treino')
plt.plot(history.history['val_accuracy'], label='ValidaÃ§Ã£o')
plt.title('EvoluÃ§Ã£o da AcurÃ¡cia')
plt.xlabel('Ã‰pocas')
plt.ylabel('AcurÃ¡cia')
plt.legend()
plt.show()

# AvaliaÃ§Ã£o final
test_loss, test_acc = mlp_model.evaluate(ds_test)
print(f"AcurÃ¡cia final no conjunto de teste: {test_acc:.4f}")

# Matriz de confusÃ£o
y_true = []
y_pred = []

for images, labels in ds_test:
    preds = mlp_model.predict(images)
    y_true.extend(labels.numpy())
    y_pred.extend((preds > 0.5).astype(int).flatten())

cm = confusion_matrix(y_true, y_pred)
ConfusionMatrixDisplay(cm, display_labels=['Gato', 'Cachorro']).plot(cmap='Blues')
plt.show()

# RelatÃ³rio de classificaÃ§Ã£o
print("\nRelatÃ³rio de ClassificaÃ§Ã£o:")
print(classification_report(y_true, y_pred, target_names=['Gato', 'Cachorro']))

"""-> Matriz de ConfusÃ£o

- Acertos do modelo:

  - 1167 gatos foram corretamente classificados como gatos.

  - 1665 cachorros foram corretamente classificados como cachorros.

- Erros do modelo:

  - 1113 gatos foram classificados como cachorros.

  - 707 cachorros foram classificados como gatos.

- O modelo estÃ¡ melhor em identificar cachorros do que gatos:

  - Ele acerta 70% dos cachorros (1665 / (1665+707)) â‰ˆ 70,2%

  - Mas acerta apenas 51% dos gatos (1167 / (1167+1113)) â‰ˆ 51,2%

DOCUMENTAÃ‡ÃƒO RESUMIDA:

1ï¸âƒ£ PRÃ‰-PROCESSAMENTO
- Imagens redimensionadas para 64x64 e normalizadas (0â€“1).
- Data Augmentation (flip horizontal e brilho aleatÃ³rio) melhora generalizaÃ§Ã£o.

2ï¸âƒ£ ARQUITETURA DA RNA
- Rede MLP densa (sem convoluÃ§Ã£o).
- 3 camadas densas com 512 â†’ 256 â†’ 128 neurÃ´nios.
- ReLU nas camadas internas e Sigmoid na saÃ­da (classificaÃ§Ã£o binÃ¡ria).
- RegularizaÃ§Ã£o L2 e Dropout evitam overfitting.

3ï¸âƒ£ TREINAMENTO
- Otimizador Adam com LR=0.0001.
- EarlyStopping interrompe antes do overfitting.
- MÃ©trica principal: AcurÃ¡cia.

4ï¸âƒ£ AVALIAÃ‡ÃƒO
- Curvas de aprendizado analisam overfitting.
- Matriz de confusÃ£o e relatÃ³rio de classificaÃ§Ã£o mostram erros do modelo.

Com essa configuraÃ§Ã£o, esperou-se acurÃ¡cia entre 0.60,
mantendo a rede puramente MLP (sem CNNs).

ReferÃªncias principais de documentaÃ§Ã£o:

-> Slides de Redes Neurais, Gemini e ChatGPT
"""